# add ray
helm repo add kuberay https://ray-project.github.io/kuberay-helm/
helm repo update
helm install kuberay-operator kuberay/kuberay-operator --version 1.0.0


# add sp to kubernetes
kubectl create secret generic my-service-principal-secret \
  --from-literal=tenantId='<tenant-id>' \
  --from-literal=clientId='<client-id>' \
  --from-literal=clientSecret='<client-secret>'


# gen nodepool
az aks nodepool add \
  --resource-group rg-x \
  --cluster-name x \
  --name fastpool \
  --node-count 0 \
  --enable-cluster-autoscaler \
  --min-count 0 \
  --max-count 99 \
  --node-vm-size "standard_d4s_v3" \
  --labels hardware=highcpu

# gen nodepool
az feature register --namespace "Microsoft.ContainerService" --name "GPUDedicatedVHDPreview"

# wait to show as registered
az feature show --namespace "Microsoft.ContainerService" --name "GPUDedicatedVHDPreview"

# refresh
az provider register --namespace Microsoft.ContainerService

az aks nodepool add \
  --resource-group rg-x \
  --cluster-name x \
  --name gpupool \
  --node-count 0 \
  --enable-cluster-autoscaler \
  --min-count 0 \
  --max-count 4 \
  --node-vm-size "standard_nc16as_t4_v3" \
  --aks-custom-headers UseGPUDedicatedVHD=true \
  --labels hardware=gpu


# change scale strategy
az aks update \
  --resource-group rg-x \
  --name x \
  --cluster-autoscaler-profile skip-nodes-with-system-pods=false skip-nodes-with-local-storage=false


# create PVC
kubectl apply -f pvc.yaml



# get pods
kubectl get pods -o wide


# find the head node and forward port
export HEAD_POD=$(kubectl get pods --selector=ray.io/node-type=head -o custom-columns=POD:metadata.name --no-headers)
echo $HEAD_POD
kubectl port-forward --address 0.0.0.0 $HEAD_POD 60421:8265 &

# load dashboard on browser:
http://localhost:60421/#/overview

# check cluster resources
kubectl exec -it $HEAD_POD -- python -c "import ray; ray.init(); print(ray.cluster_resources())"

# enter node SSH
kubectl exec -it $HEAD_POD -- /bin/bash

# find jobs
kubectl get rayjob

# find cluster
kubectl get raycluster


# rayjob
kubectl describe rayjob cpu-tuning-job

# logs from head
kubectl logs $HEAD_POD

# logs from stdout -- get name from kubectl get pods
kubectl logs cpu-tuning-job-9phfq

# prune rayjob
kubectl delete rayjob cpu-tuning-job

# stream logs
kubectl logs -f gpu-predict-job-sj6m2

# cron jobs
kubectl get cronjobs

# delete cron
kubectl delete cronjob rayjob-scheduler-cronjob 

# start immediate test
kubectl create job --from=cronjob/rayjob-scheduler-cronjob rayjob-scheduler-manual-$(date +%s)


# describe
kubectl describe cronjob rayjob-scheduler-cronjob
